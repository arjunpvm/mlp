{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "`sklearn.pipeline` module provides utilities to build a composite estimator as a chain of transformers and estimators.\n",
        "\n",
        "What is a Pipeline in Scikit-learn?\n",
        "\n",
        "- At its core, a Pipeline in sklearn is a sequential list of steps, where each step (except the last one) must be a \"transformer\" and the last step can be either a transformer or an \"estimator\" (like a model).\n",
        "- When you call fit on a Pipeline, it calls fit_transform on all transformers in order, and then fit on the final estimator.\n",
        "- When you call predict, it calls transform on all transformers and then predict on the final estimator.\n",
        "\n",
        "Why are Pipelines useful?\n",
        "\n",
        "- Convenience and Conciseness: They allow you to define a complete machine learning workflow in a single object. This makes your code cleaner and easier to read.\n",
        "- Data Leakage Prevention: This is perhaps the most crucial benefit. When you perform operations like scaling or imputation before splitting your data into training and testing sets, information from the test set can \"leak\" into the training set, leading to overly optimistic performance estimates. Pipelines ensure that transformations learned from the training data are applied consistently to new data (like the test set or future predictions), preventing this leakage.\n",
        "- Reproducibility: A well-defined pipeline makes it easy to reproduce your entire workflow, from preprocessing to model training, with new data.\n",
        "- Hyperparameter Tuning: You can easily tune hyperparameters for any step within the pipeline (e.g., the imputation strategy, the type of encoder, or the model's parameters) using GridSearchCV or RandomizedSearchCV."
      ],
      "metadata": {
        "id": "e2qSJQpvTV9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47YbAuMATU70"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'age': [25, 30, np.nan, 40, 35],\n",
        "    'salary': [50000, 60000, 45000, 70000, np.nan],\n",
        "    'city': ['A', 'B', 'A', 'C', 'B'],\n",
        "    'gender': ['M', 'F', 'M', 'F', 'M'],\n",
        "    'target': [0, 1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "X = data.drop(\"target\", axis = 1)\n",
        "y = data[\"target\"]"
      ],
      "metadata": {
        "id": "YSATuyQTUVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Pipeline"
      ],
      "metadata": {
        "id": "ou0vL6xDSi-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "numerical_transformers = Pipeline(steps=[\n",
        "    (\"impute\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categorical_transformers = Pipeline(steps= [\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OrdinalEncoder()),\n",
        "])\n",
        "\n",
        "# combine transformers using column transformer\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"numerical\", numerical_transformers, [\"age\", \"salary\"]),\n",
        "        (\"categorical\", categorical_transformers, [\"city\", \"gender\"])],\n",
        "    remainder = \"drop\") # this drops all the remaining columns\n",
        "\n",
        "# then create a full pipeline\n",
        "\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessing\", preprocessor),\n",
        "    (\"classifier\", LogisticRegression(random_state=42))\n",
        "    ])\n",
        "\n",
        "# fitting the pipeline to our data\n",
        "model_pipeline.fit(X, y)\n",
        "\n",
        "# make predictions\n",
        "predictions = model_pipeline.predict(X)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gesxGL6NH-jn",
        "outputId": "9c2dec4d-2f7a-4205-ec32-eaa2cd334f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Types of Pipelines\n",
        "- While sklearn primarily offers one Pipeline class, we can conceptualize \"types\" based on their purpose or the stage of the workflow they represent:\n",
        "\n",
        "### Preprocessing Pipelines (or Feature Engineering Pipelines):\n",
        "\n",
        "- Purpose: These pipelines focus solely on data transformation. They typically chain together various transformers like imputers, scalers, encoders, feature selectors, dimensionality reduction techniques (e.g., PCA), or custom transformers.\n",
        "- Last Step: The last step is usually a transformer, not an estimator.\n",
        "- Use Case: Often used as a step within a larger ColumnTransformer or as the first step in a complete machine learning pipeline, as shown in the numerical_transformer and categorical_transformer examples above.\n",
        "- You might fit such a pipeline on training data and then transform both training and test data.\n",
        "Python\n",
        "\n",
        "# Example of a preprocessing pipeline\n",
        "```python\n",
        "feature_engineering_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    # ('pca', PCA(n_components=2)) # Could add dimensionality reduction\n",
        "])\n",
        "```\n",
        "### Full Machine Learning Pipelines:\n",
        "- Purpose: These are comprehensive pipelines that include all steps from raw data transformation to the final model prediction.\n",
        "- Last Step: The last step is always an estimator (a machine learning model like LogisticRegression, RandomForestClassifier, etc.).\n",
        "- Use Case: This is the most common and recommended way to build your end-to-end machine learning solution. It's what you'll primarily use for training, evaluation, and deployment. The model_pipeline example above is a perfect illustration of this type.\n",
        "Python\n",
        "\n",
        "# Example of a full machine learning pipeline (similar to the one above)\n",
        "```python\n",
        "full_ml_pipeline = Pipeline(steps=[\n",
        "    ('preprocessing', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, ['age', 'salary']),\n",
        "            ('cat', categorical_transformer, ['city', 'gender'])\n",
        "        ]\n",
        "    )),\n",
        "    ('model', RandomForestClassifier(random_state=42)) # Or any other model\n",
        "])\n",
        "```\n",
        "### Nested Pipelines (Pipeline within ColumnTransformer):\n",
        "\n",
        "- Purpose: While not a \"type\" of pipeline itself, it's a very common and powerful pattern where smaller pipelines are embedded as steps within a ColumnTransformer. This allows you to apply distinct sequences of transformations to different subsets of your features.\n",
        "- Use Case: This is what you already saw in the main example, where numerical_transformer and categorical_transformer (which are themselves Pipeline objects) are used inside the ColumnTransformer. - This is extremely useful for handling mixed data types.\n",
        "- You're already familiar with ColumnTransformer, and understanding how to combine it with Pipeline to create robust and clean machine learning workflows is a crucial step in your machine learning journey.\n",
        "- Keep exploring the sklearn documentation, and don't hesitate to experiment with different transformers within your pipelines!"
      ],
      "metadata": {
        "id": "7wrp4gX1M2l8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBukuyF3Kb-v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}